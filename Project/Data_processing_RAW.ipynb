{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/bin')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/python')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/python/pyspark')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/python/lib')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/python/lib/pyspark.zip')\n",
    "sys.path.append('/home/adam/EPFL_courses/spark-1.6.3-bin-hadoop2.6/python/lib/py4j-0.9-src.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.4.5 :: Anaconda 4.3.1 (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SQLContext\n",
    "import json \n",
    "import gzip\n",
    "from pyspark.sql.functions import to_date, unix_timestamp, from_unixtime #, to_timestamp, \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "text_file = sc.textFile(\"/media/adam/B236CB1D36CAE209/Studia/ADA/reviews_Books_5.json\")\n",
    "\n",
    "# regex to get one word\n",
    "word_regex = re.compile(r'(\\w+)')\n",
    "\n",
    "# convert a text line to words vector\n",
    "def get_line_words(line):\n",
    "    return word_regex.findall(line.lower())\n",
    "\n",
    "counts_rdd = text_file.flatMap(get_line_words) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .sortBy(lambda wc: -wc[1])\n",
    "\n",
    "# convert to dataframe\n",
    "counts = sqlContext.createDataFrame(counts_rdd.map(lambda wc: Row(word=wc[0], count=wc[1])))\n",
    "\n",
    "# view the content of the dataframe\n",
    "#counts.show()\n",
    "\n",
    "# get 3 row for the dataframe\n",
    "top3 = counts.take(3)\n",
    "print(\"Top 3 words:\")\n",
    "for w in top3:\n",
    "    print(w)\n",
    "\n",
    "# save to json\n",
    "#counts.write.json(\"frankenstein_words_count.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'r') \n",
    "    for l in g:\n",
    "        yield json.loads(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_reviews = 0\n",
    "g = gzip.open(\"/home/adam/Downloads/reviews_Books_5.json.gz\")\n",
    "for l in g:\n",
    "    number_of_reviews = number_of_reviews + 1\n",
    "print(number_of_reviews)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'r') \n",
    "    for l in g: \n",
    "        yield json.dumps(eval(l))\n",
    "        \n",
    "number_of_reviews = 0\n",
    "f = open('/media/adam/B236CB1D36CAE209/Studia/ADA/reviews_Books_5_' + str(number_of_reviews) + '.json', 'w+')\n",
    "for l in parse(\"/home/adam/Downloads/reviews_Books_5.json.gz\"): \n",
    "    number_of_reviews = number_of_reviews + 1\n",
    "    if number_of_reviews % 1000000 == 0:\n",
    "        f.close()\n",
    "        f = open('/media/adam/B236CB1D36CAE209/Studia/ADA/reviews_Books_5_' + str(number_of_reviews/1000000)\n",
    "                 + '.json', 'w+')\n",
    "    f.write(l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.driver.maxResultSize', '4g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.extrajavaoptions', '-Xmx1024m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.sql.autoBroadcastJoinThreshold', '-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"/media/adam/B236CB1D36CAE209/Studia/ADA/reviews_Books_5.json\")\n",
    "df = sqlContext.read.json(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = sc.textFile(\"/media/adam/B236CB1D36CAE209/Studia/ADA/meta_Books.json\")\n",
    "metadata_df = sqlContext.read.json(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(metadata_df, \"metadata\")\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.alias('a').join(metadata_df.alias('b'),col('b.asin') == col('a.asin')).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('unixReviewTime', from_unixtime(df['unixReviewTime']))\n",
    "df = df.withColumn('reviewTime', to_date(df['unixReviewTime']))\n",
    "df = df.withColumn('unixReviewTime', df['unixReviewTime'].cast('timestamp'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.select(\"reviewTime\", 'reviewText', 'unixReviewTime').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aTuple = (0, 0)\n",
    "a = df.select(\"reviewTime\", 'reviewText').rdd.map(lambda row: (row.reviewTime, len(row.reviewText)))\n",
    "a = a.aggregateByKey(aTuple, lambda a,b: (a[0] + b, a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "a = a.mapValues(lambda v: v[0]/v[1])\n",
    "a = a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_len = pd.DataFrame(a, columns=['Date', 'Avg_length'])\n",
    "avg_len['Date'] = pd.to_datetime(avg_len['Date'])\n",
    "avg_len.set_index('Date', inplace=True)\n",
    "avg_len.sort_index(inplace=True)\n",
    "avg_len.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_len.to_csv(\"avg_length_review_by_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_data = avg_len.groupby(avg_len.index.to_period('M')).mean()\n",
    "monthly_data.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_data['2012':'2013'].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthly_data.to_csv(\"avg_length_review_by_month.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = df.rdd.filter(lambda row: row.unixReviewTime > pd.to_datetime('2012-05')\n",
    "                     and row.unixReviewTime < pd.to_datetime('2013'))\n",
    "tmp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_reviews = df.rdd.map(lambda row: (row.reviewTime, 1)).reduceByKey(lambda a, b: a+b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rev_num = pd.DataFrame(number_of_reviews, columns=['Date', 'Number of reviews'])\n",
    "rev_num['Date'] = pd.to_datetime(rev_num['Date'])\n",
    "rev_num.set_index('Date', inplace=True)\n",
    "rev_num.sort_index(inplace=True)\n",
    "rev_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rev_num.to_csv(\"number_of_reviews_per_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monthly_data_reviews = rev_num.groupby(rev_num.index.to_period('M')).sum()\n",
    "monthly_data_reviews.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthly_data_reviews.to_csv(\"number_of_reviews_per_month.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_reviews_per_book = df.rdd.map(lambda row: (row.asin, 1)).reduceByKey(lambda a, b: a+b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = df.rdd.map(lambda row: (row.asin, 1)).reduceByKey(lambda a, b: a+b).sortBy(lambda wc: -wc[1]).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = sqlContext.createDataFrame(test_df, ['asin', 'rew_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(asin='030758836X', rew_num=7440),\n",
       " Row(asin='0439023483', rew_num=6717),\n",
       " Row(asin='0375831002', rew_num=4864),\n",
       " Row(asin='038536315X', rew_num=4604),\n",
       " Row(asin='0439023513', rew_num=4440)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"select asin, title from metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(asin='030758836X', rew_num=7440, asin='0001048791', title='The Crucible: Performed by Stuart Pankin, Jerome Dempsey &amp; Cast'),\n",
       " Row(asin='030758836X', rew_num=7440, asin='0001048775', title='Measure for Measure: Complete &amp; Unabridged'),\n",
       " Row(asin='030758836X', rew_num=7440, asin='0001048236', title='The Sherlock Holmes Audio Collection'),\n",
       " Row(asin='030758836X', rew_num=7440, asin='0000401048', title=\"The rogue of publishers' row;: Confessions of a publisher (A Banner Book)\"),\n",
       " Row(asin='030758836X', rew_num=7440, asin='0001019880', title=\"Classic Soul Winner's New Testament Bible\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.join(sqlContext.sql(\"select asin, title from metadata\")).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(asin='1940026016', title='The Atlantis Gene: A Thriller (The Origin Mystery, Book 1)'),\n",
       " Row(asin='0439023483', title='The Hunger Games (The Hunger Games, Book 1)'),\n",
       " Row(asin='0316206849', title=\"The Cuckoo's Calling\"),\n",
       " Row(asin='1469984202', title='Wool - Omnibus Edition'),\n",
       " Row(asin='0141039280', title='The Help'),\n",
       " Row(asin='0385537859', title='Inferno'),\n",
       " Row(asin='038536315X', title='Sycamore Row'),\n",
       " Row(asin='0312853238', title=\"Ender's Game (The Ender Quintet)\"),\n",
       " Row(asin='0007444117', title='Allegiant (Divergent, #3)'),\n",
       " Row(asin='0316055433', title='The Goldfinch: A Novel (Pulitzer Prize for Fiction)'),\n",
       " Row(asin='0007386648', title='Unbroken'),\n",
       " Row(asin='030758836X', title='Gone Girl'),\n",
       " Row(asin='0345803485', title='Fifty Shades of Grey: Book One of the Fifty Shades Trilogy'),\n",
       " Row(asin='0425263924', title='Entwined with You (Crossfire, Book 3)'),\n",
       " Row(asin='0857521012', title='The Light Between Oceans'),\n",
       " Row(asin='0061950726', title='Orphan Train: A Novel'),\n",
       " Row(asin='0849922070', title=\"Heaven is for Real Movie Edition: A Little Boy's Astounding Story of His Trip to Heaven and Back\"),\n",
       " Row(asin='0345803493', title='Fifty Shades Darker'),\n",
       " Row(asin='147674355X', title='Hopeless'),\n",
       " Row(asin='0143170090', title='The Girl with the Dragon Tattoo'),\n",
       " Row(asin='0307943232', title='The Racketeer'),\n",
       " Row(asin='0375831002', title='The Book Thief'),\n",
       " Row(asin='0439023513', title='Mockingjay (The Final Book of The Hunger Games)'),\n",
       " Row(asin='1442362383', title='Doctor Sleep: A Novel'),\n",
       " Row(asin='1442359315', title=\"Proof of Heaven: A Neurosurgeon's Near-Death Experience and Journey into the Afterlife\"),\n",
       " Row(asin='0002007770', title='Water For Elephants'),\n",
       " Row(asin='0007442920', title='Insurgent (Divergent)'),\n",
       " Row(asin='0345803507', title='Fifty Shades Freed: Book Three of the Fifty Shades Trilogy'),\n",
       " Row(asin='144235948X', title='Beautiful Disaster'),\n",
       " Row(asin='0399159347', title=\"The Husband's Secret\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select t.asin, m.title from metadata m join test t on m.asin=t.asin\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"select t.asin, m.title from metadata m join test t limit 10\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.join(metadata_df.select(\"asin\", \"title\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(number_of_reviews_per_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_number_of_reviews_per_book = pd.DataFrame(number_of_reviews_per_book, columns=['Book_id', 'Number of reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_number_of_reviews_per_book.sort_values('Number of reviews', ascending=False, inplace = True)\n",
    "df_number_of_reviews_per_book.to_csv(\"number_of_reviews_per_book.csv\", index=False)\n",
    "df_number_of_reviews_per_book.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.array(df_number_of_reviews_per_book['Number of reviews'].values), bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.describe(df_number_of_reviews_per_book['Number of reviews'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df_number_of_reviews_per_book['Number of reviews'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_reviewed_books_id_top10 = df_number_of_reviews_per_book[:30]\n",
    "tmp = df.rdd.filter(lambda row: row.asin in list(most_reviewed_books_id_top10.Book_id)).map(lambda row: (row.asin, row.reviewTime)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = sqlContext.sql(\"select asin, reviewTime from dataset where asin in \" + \n",
    "               str(tuple(most_reviewed_books_id_top10.Book_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_reviewed_books_top20_df = pd.DataFrame(tmp, columns=['asin', 'reviewTime'])\n",
    "most_reviewed_books_top20_df['reviewTime'] = pd.to_datetime(most_reviewed_books_top20_df['reviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_reviewed_books_top20_df['Number_of_reviews'] = 1\n",
    "most_reviewed_books_top20_df['Year-month'] = most_reviewed_books_top20_df['reviewTime'].dt.to_period('M')\n",
    "most_reviewed_books_top20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_reviewed_books_top20_df.groupby(['asin', 'reviewTime']).sum().to_csv(\"number_of_reviews_per_day_top30_books.csv\")\n",
    "m_rev_books_by_month = most_reviewed_books_top20_df.groupby(['asin', 'Year-month'], as_index=True).sum()\n",
    "m_rev_books_by_month.to_csv(\"number_of_reviews_per_month_top30_books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_rev_books_by_month.unstack(level=0).to_csv(\"number_of_reviews_per_month_top30_books_UNSTACKED.csv\")\n",
    "m_rev_books_by_month.unstack(level=0).plot(figsize = (20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun = np.vectorize(lambda x: x.to_timestamp())\n",
    "m_rev_books_by_month['Timestamp'] = fun(m_rev_books_by_month['Year-month'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_rev_books_by_month.set_index('asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(most_reviewed_books_id_top10.Book_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aTuple = (0, 0)\n",
    "b = df.select('asin', 'reviewText').rdd.map(lambda row: (row.asin, len(row.reviewText)))\n",
    "b = b.aggregateByKey(aTuple, lambda a,b: (a[0] + b, a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "b = b.mapValues(lambda v: (v[0]/v[1], v[1]))\n",
    "b = b.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = [(k, v1, v2) for k, (v1, v2) in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_len_review_per_book = pd.DataFrame(b, columns=['Book_id', 'Avg_len', 'number_of_reviews'])\n",
    "avg_len_review_per_book.sort_values(['Avg_len', 'number_of_reviews'], ascending=False, inplace=True)\n",
    "avg_len_review_per_book.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_len_review_per_book.to_csv(\"avg_length_and_number_of_reviews_per_book.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
